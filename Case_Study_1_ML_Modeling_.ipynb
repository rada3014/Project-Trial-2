{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SmyRx9hO0tx"
   },
   "source": [
    "# **Mercedes-Benz Greener Manufacturing**\n",
    "##  Can you cut the time a Mercedes-Benz spends on the test bench?\n",
    "<!-- \n",
    "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/6565/media/daimler-mercedes%20V02.jpg\"/>  -->\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/6565/media/daimler-mercedes%20V02.jpg\" />\n",
    "\n",
    "<img src=\"https://i.imgur.com/EZxmFnx.jpg\" />\n",
    "\n",
    "\n",
    "Image Sources:\n",
    "1. https://storage.googleapis.com/kaggle-competitions/kaggle/6565/media/daimler-mercedes%20V02.jpg\n",
    "2. https://i.imgur.com/EZxmFnx.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svgifCjcwhvw"
   },
   "source": [
    "## **Source**: This problem statement belongs to a  a machine learning challenge which was hosted on the kaggle platform. The link is here ------>[Competition Link](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/overview)\n",
    "\n",
    "## **Topic**: A Data Driven Approach to cut the time a Mercedes-Benz spends on the test bench.\n",
    "\n",
    " ## **1. Buisness Problem** \n",
    "\n",
    "### **1.1 Overview** : \n",
    "Since the first automobile, the Benz Patent Motor Car in 1886, Mercedes-Benz has stood for important automotive innovations. These include, for example, the passenger safety cell with crumple zone, the airbag and intelligent assistance systems. Mercedes-Benz applies for nearly 2000 patents per year, making the brand the European leader among premium car makers. Daimler’s Mercedes-Benz cars are leaders in the premium car industry. With a huge selection of features and options, customers can choose the customized Mercedes-Benz of their dreams. To ensure the safety and reliability of each and every unique car configuration before they hit the road, Daimler’s engineers have developed a robust testing system. But, optimizing the speed of their testing system for so many possible feature combinations is complex and time-consuming without a powerful algorithmic approach. As one of the world’s biggest manufacturers of premium cars, safety and efficiency are paramount on Daimler’s production lines.\n",
    "\n",
    " \n",
    "### **1.2 Problem Statement** : \n",
    "- Safety and reliability testing is a crucial step in the automobile manufacturing process. Every new vehicle design must pass a thorough evaluation before it enters the consumer market. Testing can be time-consuming and cost-intensive as a full check of vehicle systems requires subjecting the car to all situations it will encounter in its intended use. \n",
    "\n",
    "- Predicting the overall time for a vehicle to pass testing is difficult because each model requires a different test stand configuration. Mercedes-Benz has been a pioneer of numerous vehicle safety and technology features and offers a range of custom options for each model. Every possible vehicle combination must undergo the same rigorous testing to ensure the vehicle is robust enough to keep occupants safe and withstand the rigors of daily use. \n",
    "\n",
    "- The large array of options offered by Mercedes means a large number of tests for the company’s engineers to conduct. More tests result in more time spent on the test stand, increasing costs for Mercedes and generating carbon dioxide, a polluting greenhouse gas. Efforts by Mercedes Benz and other automakers to improve the efficiency of vehicle testing procedures have mainly focusing on developing automated test systems.\n",
    "\n",
    "- An automatic test system eliminates the variability inherent in human behavior, is safer than allowing humans in the driver’s seat, and results in an overall more efficient evaluation process.\n",
    "\n",
    "- The **objective** of this competition is **to develop a machine learning model** that can accurately predict the time a car will spend on the test bench based on the vehicle configuration. \n",
    "\n",
    "- The vehicle configuration is defined as the set of customization options and features selected for the particular vehicle. The motivation behind the problem is that an accurate model will be able to reduce the total time spent testing vehicles by allowing cars with similar testing configurations to be run successively. \n",
    "\n",
    "- This problem is an example of a machine learning regression task because it requires predicting a continuous target variable (the duration of the test) based on one or more explanatory variables(the configuration of the vehicle). This problem is also a supervised task because the targets for the training data are known ahead of time and the model will learn based on labeled data\n",
    "\n",
    "\n",
    "\n",
    "### **1.3 Business Objective and Contraints**\n",
    " - Our objective is  to predict the time that a mercedes benz vehicle spends on a test bench.\n",
    " - No strict latency constraints but the prediction time should be less than few minutes.\n",
    "\n",
    "\n",
    "## **2 Machine Learning Problem:**\n",
    "\n",
    "### **2.1 Data Overview :**\n",
    "This dataset contains an anonymized set of variables, each representing a custom feature in a Mercedes car. For example, a variable could be 4WD, added air suspension, or a head-up display.\n",
    "The ground truth is labeled ‘y’ and represents the time (in seconds) that the car took to pass testing for each variable.\n",
    "We have two CSV files:\n",
    "**train.csv** — Contains the training set with 4209 rows (data points) and 378 columns (features) with labels.\n",
    "**test.csv** — Contains the test set with 4209 rows (data points) and 377 columns (features) with no labels.\n",
    "\n",
    "[Dataset](https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/data)\n",
    "\n",
    "### **2.2 Performance Metrics**\n",
    "\n",
    "**Specific to Competition**: In order to test any machine/deep learning model's performance we monitor a metrics value, so we know how bad or good our model's performance is on a given datset and based on that we can fine tune our model .In this competition it has been told that our model performance is analysed on R^2 score. R^2 Score is a widely used metric when it comes to analyze any model's performance which is designed to perform regression task.\n",
    "\n",
    "\n",
    "- R^2 is also known as Coefficient of Determination, R-squared gives the percentage variation in ‘y’ (test time in this case) explained by ‘x-variables’ (combination of car custom features in this case). In simple words R^2 gives us the percentage of data points that fall within the regression line. The higher the R^2 value, higher will be the data points that fall within the line. E.g. if R^2 value is 0.45 then it indicates that 45% data points are lying within the regression line of the total data points. Mathematically R^2 is denoted as follows:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/FJGsT86.png\" width=\"350\" height=\"400\"/>\n",
    "\n",
    "\n",
    " -There are 4 possible scenarios possible with R^2 Score:\n",
    "\n",
    "\n",
    " <img src=\"https://i.imgur.com/IUxpJjI.png\" width=\"400\" height=\"900\"/>\n",
    "\n",
    "\n",
    " - R^2 Score is highly sensitive to outliers.The algorithm that best explains the variation in testing times will be the optimal machine learning model for the task. So this is the best metric to be used for evaluation in this problem, as Mercedes is really interested to know how the different testing times for different configurations can be represented using a machine learning model.\n",
    "\n",
    "- In the cases above there is one case(case-4)  in which it is mentioned that R^2 score can be negative in certain cases, which means that our model is  predicting even worse that the mean of the target variable that is why it is called the worst model so we have to strictly avoid such models.\n",
    "\n",
    "- R^2 metric upper bound is 1 but in case of RMSE and MAE, score ranges from 0 to ∞(infinity) there is no upper bound so it will be difficult for us to compare the model with baseline model score. The benifit of using R^2 metric is that it is having an upper bound 1 beyond which the score cannot increase so we can compare our model score with the baseline model score, hence R^2 metric is preffered over RMSE and MAE in this problem.\n",
    "\n",
    "\n",
    "**Not Specific to Competition:** There is one more very interesting metric which fits here and that is **RMLSE ( Root Mean Log Square Error)**. \n",
    "\n",
    "It's formulation is like this:\n",
    "\n",
    "\n",
    "\n",
    " <img src=\"https://miro.medium.com/max/4800/0*AUzyQ1rc6mpQVYfn\" width=\"500\" height=\"150\"/>\n",
    "\n",
    " Note that in the formulation X is the predicted value and Y is the actual value.\n",
    "\n",
    " RMSLE incurs a larger penalty for the underestimation of the Actual variable than the Overestimation.\n",
    "\n",
    "- lets see an example of this.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://i.imgur.com/FBmh0T9.png\" width=\"350\" height=\"550\"/>\n",
    "\n",
    "\n",
    " From these two cases, it is evident that the RMLSE incurs a larger penalty for the underestimation of the actual value. \n",
    "\n",
    " So that is what it makes this metric relevent here because since we cannot afford underestimating the time a vehicle spends at the test bench because in that case it can so happen that a vehicle won't undergo all the necessary test on a test bench and which we surely dont want, but that doestn't also mean that we can overestimate every single time but yes sometimes we can afford to. Ideally we should predict as close as we can to the actual value in order to efficiently solve this problem using Machine Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_wijKruhTKD"
   },
   "source": [
    "## Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JiyCU0dwnJva"
   },
   "outputs": [],
   "source": [
    "\n",
    "#loading important packages.\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pylab \n",
    "import scipy.stats as stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "color = sns.color_palette()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "color = sns.color_palette()\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import pyplot\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "%matplotlib inline\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.max_columns = 999\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LinearRegression,Ridge,Lasso,ElasticNet,RidgeCV,LassoCV\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from prettytable import PrettyTable\n",
    "#import lightgbm as lgb \n",
    "from sklearn.ensemble import GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LassoCV,Ridge\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.random_projection import GaussianRandomProjection,SparseRandomProjection\n",
    "\n",
    "from numpy import load,save\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QxihZ0QQ-DA8"
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3F8g0KmQkaYE",
    "outputId": "d3b69fed-deb4-4d2f-dcb1-fb64ddcf1aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #Mounting Google Drive \n",
    "\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nd_3u0wNmsGQ",
    "outputId": "ece50df8-f5e0-4fe9-a204-29ba20750fcc"
   },
   "outputs": [],
   "source": [
    "#cd \"/content/gdrive/MyDrive/Applied/Case Study-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxRFiGk7DSuM"
   },
   "outputs": [],
   "source": [
    "#training and test dataset \n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "\n",
    "train_cleaned = train[train['y']<150]\n",
    "y_train = train_cleaned['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmgmH9rKq0vw"
   },
   "source": [
    "#Feature sets\n",
    "\n",
    "1. Original Features+Interactions\n",
    "\n",
    "\n",
    "2. Original Features + Projections  (ICA+PCA+SVD+GRP+SRP) + Interactions\n",
    "\n",
    "3. Feature Selection features + Projections  (ICA+PCA+SVD+GRP+SRP) + Interactions\n",
    "\n",
    "4. Original Features+Interactions + PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lw6MloVNWRGA"
   },
   "outputs": [],
   "source": [
    "train_set_1,test_set_1=pd.read_csv('train_set_1.csv'),pd.read_csv('test_set_1.csv')\n",
    "train_set_2,test_set_2=pd.read_csv('train_set_2.csv'),pd.read_csv('test_set_2.csv')\n",
    "train_set_4,test_set_4=pd.read_csv('train_set_4.csv'),pd.read_csv('test_set_4.csv')\n",
    "train_set_3,test_set_3=np.load('train_set_3.npy'),np.load('test_set_3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1EBnogDiMCBT",
    "outputId": "a25e97d2-d3a0-4139-b0f7-c3335eb87aba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set 1 is: (4194, 329)\n",
      "Shape of test set 1 is: (4209, 329)\n",
      "***************************************\n",
      "Shape of training set 2 is: (4194, 653)\n",
      "Shape of test set 2 is: (4209, 653)\n",
      "***************************************\n",
      "Shape of training set 3 is: (4194, 417)\n",
      "Shape of test set 3 is: (4209, 417)\n",
      "***************************************\n",
      "Shape of training set 4 is: (4194, 379)\n",
      "Shape of test set 4 is: (4209, 379)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training set 1 is:\",train_set_1.shape)\n",
    "print(\"Shape of test set 1 is:\",test_set_1.shape)\n",
    "print(\"***************************************\")\n",
    "print(\"Shape of training set 2 is:\",train_set_2.shape)\n",
    "print(\"Shape of test set 2 is:\",test_set_2.shape)\n",
    "print(\"***************************************\")\n",
    "print(\"Shape of training set 3 is:\",train_set_3.shape)\n",
    "print(\"Shape of test set 3 is:\",test_set_3.shape)\n",
    "print(\"***************************************\")\n",
    "print(\"Shape of training set 4 is:\",train_set_4.shape)\n",
    "print(\"Shape of test set 4 is:\",test_set_4.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pORe17o5PA_N"
   },
   "source": [
    "\n",
    "# 8 Machine Learning Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOfOZl6G38gO"
   },
   "source": [
    "## Base Line Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sX_ymA11jg-"
   },
   "source": [
    "## 8.1 K Nearest Neighbour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFN2N61TJFcu"
   },
   "source": [
    "### 1. Original Features+Interactions (set-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pAMYSxqnDYnp",
    "outputId": "9caa4995-62f5-4844-cd86-f8621af8e432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   38.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 40\n",
      "Best p: 1\n",
      "Best n_neighbors: 26\n",
      "Time Taken: 38.89311408996582\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(knn, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_1,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_leaf_size =best_model.best_estimator_.get_params()['leaf_size']\n",
    "best_norm =best_model.best_estimator_.get_params()['p']\n",
    "best_K =   best_model.best_estimator_.get_params()['n_neighbors']\n",
    "\n",
    "print('Best leaf_size:', best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LyqTt2V3D97P",
    "outputId": "8361977d-1cf6-426a-ab19-09b2b4020b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Knn Regressor with best parameters\n",
      "Best leaf_size: 40\n",
      "Best p: 1\n",
      "Best n_neighbors: 26\n",
      "R2 score on train dataset is: 0.6103341865763634\n",
      "R2 score on cv dataset is: 0.5671906182969432\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "knn = KNeighborsRegressor(n_neighbors=best_K, leaf_size=best_leaf_size, p=best_norm)\n",
    "knn.fit(train_set_1, y_train)\n",
    "\n",
    "\n",
    "scores = cross_val_score(knn, train_set_1, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = knn.predict(train_set_1)\n",
    "\n",
    "print(\"Predictions on Knn Regressor with best parameters\")\n",
    "print('Best leaf_size:',best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbfCIvpFNUsf"
   },
   "outputs": [],
   "source": [
    "y_test=knn.predict(test_set_1)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('knn_set_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTgr-rJz2ouq"
   },
   "source": [
    "### 2. Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vvYtHLfiJDmA",
    "outputId": "f23f7915-32b0-4393-b2ee-80de89e61761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   40.7s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   51.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 38\n",
      "Best p: 1\n",
      "Best n_neighbors: 10\n",
      "Time Taken: 68.75650310516357\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(knn, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_2,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_leaf_size =best_model.best_estimator_.get_params()['leaf_size']\n",
    "best_norm =best_model.best_estimator_.get_params()['p']\n",
    "best_K =   best_model.best_estimator_.get_params()['n_neighbors']\n",
    "\n",
    "print('Best leaf_size:', best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "\n",
    "# y_pred = best_model.predict(X_cv_prepr)\n",
    "\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9BYO4aaJu89",
    "outputId": "eef9db60-0862-4621-8d9a-438eb2a4e5b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Knn Regressor with best parameters\n",
      "Best leaf_size: 38\n",
      "Best p: 1\n",
      "Best n_neighbors: 10\n",
      "R2 score on train dataset is: 0.5973105069396064\n",
      "R2 score on cv dataset is: 0.47253436716651276\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "knn = KNeighborsRegressor(n_neighbors=best_K, leaf_size=best_leaf_size, p=best_norm)\n",
    "knn.fit(train_set_2, y_train)\n",
    "\n",
    "\n",
    "scores = cross_val_score(knn, train_set_2, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = knn.predict(train_set_2)\n",
    "\n",
    "print(\"Predictions on Knn Regressor with best parameters\")\n",
    "print('Best leaf_size:',best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_QD6EgANexg"
   },
   "outputs": [],
   "source": [
    "y_test=knn.predict(test_set_2)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('knn_set_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XycXxzjQKIbh"
   },
   "source": [
    "### 3. Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z66ghr0hKIKP",
    "outputId": "5275ef30-b830-40f4-976c-37a73b57b2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   35.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   39.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 27\n",
      "Best p: 1\n",
      "Best n_neighbors: 7\n",
      "Time Taken: 39.3080358505249\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(knn, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_3,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_leaf_size =best_model.best_estimator_.get_params()['leaf_size']\n",
    "best_norm =best_model.best_estimator_.get_params()['p']\n",
    "best_K =   best_model.best_estimator_.get_params()['n_neighbors']\n",
    "\n",
    "print('Best leaf_size:', best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "\n",
    "\n",
    "# y_pred = best_model.predict(X_cv_prepr)\n",
    "\n",
    "\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jjuHxWh3KS_0",
    "outputId": "130ffadc-a705-4be1-a91d-cbaf89b35a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Knn Regressor with best parameters\n",
      "Best leaf_size: 27\n",
      "Best p: 1\n",
      "Best n_neighbors: 7\n",
      "R2 score on train dataset is: 0.625059638407744\n",
      "R2 score on cv dataset is: 0.4629133662855208\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "knn = KNeighborsRegressor(n_neighbors=best_K, leaf_size=best_leaf_size, p=best_norm)\n",
    "knn.fit(train_set_3, y_train)\n",
    "\n",
    "\n",
    "scores = cross_val_score(knn, train_set_3, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = knn.predict(train_set_3)\n",
    "\n",
    "print(\"Predictions on Knn Regressor with best parameters\")\n",
    "print('Best leaf_size:',best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "biP4TfGgNoAl"
   },
   "outputs": [],
   "source": [
    "y_test=knn.predict(test_set_3)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('knn_set_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_TVIoJn7ppQ"
   },
   "source": [
    "### 4. Original Features+Interactions + PCA (set-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WI-YWQX37bup",
    "outputId": "ba136f1b-df74-47e1-9a36-7334db982a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   58.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 15\n",
      "Best p: 1\n",
      "Best n_neighbors: 29\n",
      "Time Taken: 58.65828800201416\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors = list(range(1,30))\n",
    "p=[1,2]\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "#Create new KNN object\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(knn, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_4,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_leaf_size =best_model.best_estimator_.get_params()['leaf_size']\n",
    "best_norm =best_model.best_estimator_.get_params()['p']\n",
    "best_K =   best_model.best_estimator_.get_params()['n_neighbors']\n",
    "\n",
    "print('Best leaf_size:', best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "\n",
    "\n",
    "# y_pred = best_model.predict(X_cv_prepr)\n",
    "\n",
    "\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQ87GOPK9L5a",
    "outputId": "31e1e966-8187-4109-f283-b0c915925a7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Knn Regressor with best parameters\n",
      "Best leaf_size: 15\n",
      "Best p: 1\n",
      "Best n_neighbors: 29\n",
      "R2 score on train dataset is: 0.585981707988094\n",
      "R2 score on cv dataset is: 0.5402159777715244\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "knn = KNeighborsRegressor(n_neighbors=best_K, leaf_size=best_leaf_size, p=best_norm)\n",
    "knn.fit(train_set_4, y_train)\n",
    "\n",
    "\n",
    "scores = cross_val_score(knn, train_set_4, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = knn.predict(train_set_4)\n",
    "\n",
    "print(\"Predictions on Knn Regressor with best parameters\")\n",
    "print('Best leaf_size:',best_leaf_size)\n",
    "print('Best p:',best_norm )\n",
    "print('Best n_neighbors:',best_K)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred_cv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1bLTpNiNuAw"
   },
   "outputs": [],
   "source": [
    "y_test=knn.predict(test_set_4)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('knn_set_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-r_USFb4CB-",
    "outputId": "de841f85-4aa2-4d3c-838b-6afbb14afb1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+-------+---------+---------+\n",
      "|                                  Feature Set                                  | Model | Private |  Public |\n",
      "+-------------------------------------------------------------------------------+-------+---------+---------+\n",
      "|                         Original Features+Interactions                        |  KNN  | 0.50414 | 0.52808 |\n",
      "|      Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions     |  KNN  | 0.43260 | 0.45090 |\n",
      "| Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions |  KNN  | 0.41756 | 0.43052 |\n",
      "|                      Original Features+Interactions + PCA                     |  KNN  | 0.48654 | 0.50760 |\n",
      "+-------------------------------------------------------------------------------+-------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "x = PrettyTable()\n",
    "\n",
    "column_names = [\"Feature Set\", \"Model\", \"Private\", \"Public\"]\n",
    "\n",
    "x.add_column(column_names[0], [\"Original Features+Interactions\", \"Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original Features+Interactions + PCA\"])\n",
    "x.add_column(column_names[1], [\"KNN\", \"KNN\", \"KNN\", \"KNN\"])  \n",
    "x.add_column(column_names[2], [\"0.50414\",\"0.43260\",\"0.41756\",\"0.48654\"])  \n",
    "x.add_column(column_names[3], [\"0.52808\",\"0.45090\",\"0.43052\",\"0.50760\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yhH_9s4nJKSp"
   },
   "source": [
    "<img src=\"https://i.imgur.com/zKLokwj.png\" />\n",
    "\n",
    "\n",
    "- we can see the for the set-1 and set-4 our baseline model is performing pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlYNXVF133DR"
   },
   "source": [
    "## 8.2 Lasso Regression\n",
    " Lasso Regression is Linear regression only which is L1 Regularized so this kind of regression tries to penalizes the model whenever the weights becomes very high.\n",
    "\n",
    "Why I have choosen this model because we are well aware that L1 causes sparsity in the weights and it tries to make weights which are unimportant as zero. so here in our case since we have a problem of curse of dimensionality this method will internally help to select ony those features which are important for prediction by making the weights of unimportant features as 0. And also in the feature selection section under embedded methods we saw that how we can use this method for feature selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boMSI5H4FNWU"
   },
   "source": [
    "### 1. Original Features+Interactions (set-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEBk7rnwHEZ4",
    "outputId": "0365f3b6-b90f-442e-f6c9-b81ce856fadb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n alphas: 100\n",
      "Best eps: 0.0001\n",
      "Best selection: cyclic\n",
      "Time Taken: 246.90849947929382\n"
     ]
    }
   ],
   "source": [
    "# n_alphas = [10,20,50,100,120,150,200,250,300]\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "n_alphas = list(range(50,500,50))\n",
    "selection = ['cyclic','random']\n",
    "eps=[0.1,0.01,0.001,0.0001,0.000001,0.005,0.05,0.00005,1]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_alphas=n_alphas, eps=eps, selection=selection)\n",
    "\n",
    "#Create new KNN object\n",
    "Lasso = LassoCV()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(Lasso, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_1,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_n_alphas =best_model.best_estimator_.get_params()['n_alphas']\n",
    "best_eps =best_model.best_estimator_.get_params()['eps']\n",
    "best_selection =   best_model.best_estimator_.get_params()['selection']\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "\n",
    "# y_pred = best_model.predict(X_cv_prepr)\n",
    "\n",
    "\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QQ8X93XMBV8",
    "outputId": "2cbefd27-ab42-41f9-dea1-d4ae42c23275"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on LassoCV Regressor with best parameters\n",
      "Best n alphas: 100\n",
      "Best eps: 0.0001\n",
      "Best selection: cyclic\n",
      "R2 score on train dataset is: 0.6214923586442543\n",
      "R2 score on cv dataset is: 0.6055944678401538\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "Lcv_set_1 = LassoCV(n_alphas=best_n_alphas, eps=best_eps, selection=best_selection)\n",
    "Lcv_set_1.fit(train_set_1, y_train)\n",
    "\n",
    "scores = cross_val_score(Lcv_set_1, train_set_1, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = Lcv_set_1.predict(train_set_1)\n",
    "\n",
    "print(\"Predictions on LassoCV Regressor with best parameters\")\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYyslqxkYwea",
    "outputId": "526eafab-f3ae-44a9-abf8-0ce28a4dd64b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lcv_set_1.joblib']"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(Lcv_set_1, 'lcv_set_1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKPYj8HGNxPe"
   },
   "outputs": [],
   "source": [
    "y_test=Lcv_set_1.predict(test_set_1)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('Lcv_set_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weug7lRlNRL3"
   },
   "source": [
    "### 2. Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ir_gkG_fNb52",
    "outputId": "68cb45f3-e7b2-4d40-a111-28bb4f12f459"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  9.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 17.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n alphas: 50\n",
      "Best eps: 1e-06\n",
      "Best selection: random\n",
      "Time Taken: 1071.1233649253845\n"
     ]
    }
   ],
   "source": [
    "# n_alphas = [10,20,50,100,120,150,200,250,300]\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "n_alphas = list(range(50,500,50))\n",
    "selection = ['cyclic','random']\n",
    "eps=[0.1,0.01,0.001,0.0001,0.000001,0.005,0.05,0.00005,1]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_alphas=n_alphas, eps=eps, selection=selection)\n",
    "\n",
    "#Create new KNN object\n",
    "Lasso = LassoCV()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(Lasso, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_2,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_n_alphas =best_model.best_estimator_.get_params()['n_alphas']\n",
    "best_eps =best_model.best_estimator_.get_params()['eps']\n",
    "best_selection =   best_model.best_estimator_.get_params()['selection']\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "\n",
    "# y_pred = best_model.predict(X_cv_prepr)\n",
    "\n",
    "\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0I_NEoH7Nvjq",
    "outputId": "f8c4a89e-fd3d-45c5-ee7c-5b3b78825a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on LassoCV Regressor with best parameters\n",
      "Best n alphas: 50\n",
      "Best eps: 1e-06\n",
      "Best selection: random\n",
      "R2 score on train dataset is: 0.6238900505200372\n",
      "R2 score on cv dataset is: 0.6046695345280713\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "Lcv = LassoCV(n_alphas=best_n_alphas, eps=best_eps, selection=best_selection)\n",
    "Lcv.fit(train_set_2, y_train)\n",
    "\n",
    "scores = cross_val_score(Lcv, train_set_2, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = Lcv.predict(train_set_2)\n",
    "\n",
    "print(\"Predictions on LassoCV Regressor with best parameters\")\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rF9s0Nlwc3MQ",
    "outputId": "fbc6b53b-51ab-44ed-e85e-546a744b1f0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lcv_set_2.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(Lcv, 'lcv_set_2.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqfpENNUT9jL"
   },
   "outputs": [],
   "source": [
    "y_test=Lcv.predict(test_set_2)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('Lcv_set_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzARXIkbU3hg"
   },
   "source": [
    "### 3. Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-3)**bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhQKT83oU3Ai",
    "outputId": "b9acfecc-74cd-4117-ebbe-0b635c74f4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   26.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   56.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n alphas: 50\n",
      "Best eps: 0.0001\n",
      "Best selection: cyclic\n",
      "Time Taken: 512.560225725174\n"
     ]
    }
   ],
   "source": [
    "# n_alphas = [10,20,50,100,120,150,200,250,300]\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "n_alphas = list(range(50,500,50))\n",
    "selection = ['cyclic','random']\n",
    "eps=[0.1,0.01,0.001,0.0001,0.000001,0.005,0.05,0.00005,1]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_alphas=n_alphas, eps=eps, selection=selection)\n",
    "\n",
    "#Create new KNN object\n",
    "Lasso = LassoCV()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(Lasso, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_3,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_n_alphas =best_model.best_estimator_.get_params()['n_alphas']\n",
    "best_eps =best_model.best_estimator_.get_params()['eps']\n",
    "best_selection =   best_model.best_estimator_.get_params()['selection']\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "\n",
    "# y_pred = best_model.predict(X_cv_prepr)\n",
    "\n",
    "\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZBVy1tTU8pX",
    "outputId": "7e9648c4-e35c-4355-d269-6c49d324af20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on LassoCV Regressor with best parameters\n",
      "Best n alphas: 50\n",
      "Best eps: 0.0001\n",
      "Best selection: cyclic\n",
      "R2 score on train dataset is: 0.6237091639392022\n",
      "R2 score on cv dataset is: 0.604320548892986\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "Lcv = LassoCV(n_alphas=best_n_alphas, eps=best_eps, selection=best_selection)\n",
    "Lcv.fit(train_set_3, y_train)\n",
    "\n",
    "scores = cross_val_score(Lcv, train_set_3, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = Lcv.predict(train_set_3)\n",
    "\n",
    "print(\"Predictions on LassoCV Regressor with best parameters\")\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdUJvAKAdAAc",
    "outputId": "2aea3b3f-f3c6-4c66-8274-dbae7b7f41db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lcv_set_3.joblib']"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(Lcv, 'lcv_set_3.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCu5N_ptW115"
   },
   "outputs": [],
   "source": [
    "y_test=Lcv.predict(test_set_3)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('lcv_set_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fW869Exf9kLg"
   },
   "source": [
    "### 4. Original Features+Interactions + PCA (set-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oci70SGK9jK6",
    "outputId": "5d6d9bd5-9d83-4b28-d470-03837cba75d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n alphas: 50\n",
      "Best eps: 1e-06\n",
      "Best selection: random\n",
      "Time Taken: 189.51028490066528\n"
     ]
    }
   ],
   "source": [
    "# n_alphas = [10,20,50,100,120,150,200,250,300]\n",
    "\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#List Hyperparameters that we want to tune.\n",
    "n_alphas = list(range(50,500,50))\n",
    "selection = ['cyclic','random']\n",
    "eps=[0.1,0.01,0.001,0.0001,0.000001,0.005,0.05,0.00005,1]\n",
    "\n",
    "#Convert to dictionary\n",
    "hyperparameters = dict(n_alphas=n_alphas, eps=eps, selection=selection)\n",
    "\n",
    "#Create new KNN object\n",
    "Lasso = LassoCV()\n",
    "\n",
    "#Use Randomized Search\n",
    "reg = RandomizedSearchCV(Lasso, hyperparameters,verbose=10, cv=5,n_jobs=-1)\n",
    "\n",
    "#Fit the model\n",
    "best_model = reg.fit(train_set_4,y_train)\n",
    "\n",
    "#Print The value of best Hyperparameters\n",
    "best_n_alphas =best_model.best_estimator_.get_params()['n_alphas']\n",
    "best_eps =best_model.best_estimator_.get_params()['eps']\n",
    "best_selection =   best_model.best_estimator_.get_params()['selection']\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "\n",
    "# y_pred = best_model.predict(X_cv_prepr)\n",
    "\n",
    "\n",
    "print(\"Time Taken:\",(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iFClLKI9-UoH",
    "outputId": "57864fe1-7903-4086-e06d-b0002377451d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on LassoCV Regressor with best parameters\n",
      "Best n alphas: 50\n",
      "Best eps: 1e-06\n",
      "Best selection: random\n",
      "R2 score on train dataset is: 0.6237234606722828\n",
      "R2 score on cv dataset is: 0.6050958845858819\n"
     ]
    }
   ],
   "source": [
    "#lets use best parameters found above\n",
    "Lcv = LassoCV(n_alphas=best_n_alphas, eps=best_eps, selection=best_selection)\n",
    "Lcv.fit(train_set_4, y_train)\n",
    "\n",
    "scores = cross_val_score(Lcv, train_set_4, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = Lcv.predict(train_set_4)\n",
    "\n",
    "print(\"Predictions on LassoCV Regressor with best parameters\")\n",
    "\n",
    "print('Best n alphas:', best_n_alphas)\n",
    "print('Best eps:',best_eps )\n",
    "print('Best selection:',best_selection)\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql_eJ8VO-f8J"
   },
   "outputs": [],
   "source": [
    "y_test=Lcv.predict(test_set_4)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('lcv_set_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCU-dcpj_YWu",
    "outputId": "f1f1f10d-d459-4692-f198-85d451d05c80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lcv_set_4.joblib']"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(Lcv, 'lcv_set_4.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJgFh4Bh5mK-",
    "outputId": "6e813abb-1aab-4fc3-d752-dff6e4f60b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+---------+---------+---------+\n",
      "|                                  Feature Set                                  |  Model  | Private |  Public |\n",
      "+-------------------------------------------------------------------------------+---------+---------+---------+\n",
      "|                         Original Features+Interactions                        | LassoCV | 0.53576 | 0.53580 |\n",
      "|      Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions     | LassoCV | 0.53546 | 0.53337 |\n",
      "| Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions | LassoCV | 0.53490 | 0.53257 |\n",
      "|                      Original Features+Interactions + PCA                     | LassoCV | 0.53635 | 0.53510 |\n",
      "+-------------------------------------------------------------------------------+---------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "x = PrettyTable()\n",
    "\n",
    "column_names = [\"Feature Set\", \"Model\", \"Private\", \"Public\"]\n",
    "\n",
    "x.add_column(column_names[0], [\"Original Features+Interactions\", \"Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original Features+Interactions + PCA\"])\n",
    "x.add_column(column_names[1], [\"LassoCV\", \"LassoCV\", \"LassoCV\", \"LassoCV\"])  \n",
    "x.add_column(column_names[2], [\"0.53576\",\"0.53546\",\"0.53490\",\"0.53635\"])  \n",
    "x.add_column(column_names[3], [\"0.53580\",\"0.53337\",\"0.53257\",\"0.53510\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THe9lxitI_TV"
   },
   "source": [
    "\n",
    "- Performing Way Better than our baseline KNN.\n",
    "\n",
    "<img src=\"https://i.imgur.com/NX3Te2l.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hORi7jt3Y6AK"
   },
   "source": [
    "## 8.3 Decession Tree Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9r6GfG8Z4mZ"
   },
   "source": [
    "#### 1. Original Features+Interactions (set-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6JrBmoOrY5fc",
    "outputId": "30d4dc64-05c9-4a39-e7cd-3bcffc016621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0355s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0724s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too slow (6.8741s.) Setting batch_size=1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 2\n",
      "Best criterion: friedman_mse\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 2\n",
      "Best min_samples_leaf: 10\n",
      "Time elapsed: 32.34185552597046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.2s finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Number of trees in random forest\n",
    "start=time.time()\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "#criterion\n",
    "criterion=[\"mse\", \"friedman_mse\",\"mae\", \"poisson\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = { 'criterion':criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "dr = DecisionTreeRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(dr, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_1, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_criterion = best_regressor.best_estimator_.get_params()['criterion']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best criterion:', best_criterion)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "daL6VYmPajYA",
    "outputId": "817f4475-f1df-4029-e0dc-00450694b1d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='friedman_mse', max_depth=2,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=10, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(criterion = best_criterion,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "dt.fit(train_set_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXw0Qkboa3kh",
    "outputId": "dd005989-0922-42b0-d9f4-7436266f55f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Decision Tree with best parameters\n",
      "R2 score on train dataset is: 0.6237287170583592\n",
      "R2 score on cv dataset is: 0.6197389754659284\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt, train_set_1, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = dt.predict(train_set_1)\n",
    "\n",
    "print(\"Predictions on Decision Tree with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYc8uEkEbIvg",
    "outputId": "70366ec1-4469-49d0-8cd6-fbb16153b068"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_set_1.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dump(dt, 'dt_set_1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSFlvgc4bRte"
   },
   "outputs": [],
   "source": [
    "dt_set1=load('dt_set_1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x1VlpfvebVSR",
    "outputId": "6d901d06-d3ef-42f3-9881-535d8bde785a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Decision Tree  with best parameters\n",
      "R2 score on train dataset is: 0.6237287170583592\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = dt_set1.predict(train_set_1)\n",
    "\n",
    "print(\"Predictions on Decision Tree  with best parameters\")\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYWhegPEYG0g"
   },
   "outputs": [],
   "source": [
    "y_test=dt.predict(test_set_1)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('dt_set_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zzdDG8inbkS7"
   },
   "source": [
    "### 2. Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWv5mWEqbosq",
    "outputId": "55aa9ee9-59c6-4ab9-c4e9-91313c8276c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 3\n",
      "Best criterion: friedman_mse\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 3\n",
      "Best min_samples_leaf: 3\n",
      "Time elapsed: 101.39801692962646\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Number of trees in random forest\n",
    "start=time.time()\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "#criterion\n",
    "criterion=[\"mse\", \"friedman_mse\",\"mae\", \"poisson\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = { 'criterion':criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "dr = DecisionTreeRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(dr, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_2, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_criterion = best_regressor.best_estimator_.get_params()['criterion']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best criterion:', best_criterion)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXyQPL2eb3mx",
    "outputId": "7c50f8ec-111d-43b9-8a42-50b802da8255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Decision Tree with best parameters\n",
      "R2 score on train dataset is: 0.632523268958323\n",
      "R2 score on cv dataset is: 0.6088100679931563\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(criterion = best_criterion,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "dt.fit(train_set_2, y_train)\n",
    "\n",
    "scores = cross_val_score(dt, train_set_2, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = dt.predict(train_set_2)\n",
    "\n",
    "print(\"Predictions on Decision Tree with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7K1mDq-cDpo",
    "outputId": "9b612530-6379-47b5-8c09-607cd774bf2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_set_2.joblib']"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dump(dt, 'dt_set_2.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhCQ91RpZ09U"
   },
   "outputs": [],
   "source": [
    "y_test=dt.predict(test_set_2)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('dt_set_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aFeR98icsB1"
   },
   "source": [
    "### 3. Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzV06AiYcqyE",
    "outputId": "9a279416-bc99-4caa-95cd-3365b89c4795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 2\n",
      "Best criterion: friedman_mse\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 15\n",
      "Best min_samples_leaf: 10\n",
      "Time elapsed: 334.0732727050781\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Number of trees in random forest\n",
    "start=time.time()\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "#criterion\n",
    "criterion=[\"mse\", \"friedman_mse\",\"mae\", \"poisson\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = { 'criterion':criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "dr = DecisionTreeRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(dr, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_3, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_criterion = best_regressor.best_estimator_.get_params()['criterion']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best criterion:', best_criterion)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JAWVspnvc5D1",
    "outputId": "0702c9cc-8538-4085-9059-5ab24ef075c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Decision Tree with best parameters\n",
      "R2 score on train dataset is: 0.6237287170583592\n",
      "R2 score on cv dataset is: 0.6191973685880623\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(criterion = best_criterion,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "dt.fit(train_set_3, y_train)\n",
    "\n",
    "scores = cross_val_score(dt, train_set_3, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = dt.predict(train_set_3)\n",
    "\n",
    "print(\"Predictions on Decision Tree with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLUlNV63dGAH",
    "outputId": "8486a9f8-dd49-4cb3-d21d-6938844fb023"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_set_3.joblib']"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dump(dt, 'dt_set_3.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sG_OQ9onaG-k"
   },
   "outputs": [],
   "source": [
    "y_test=dt.predict(test_set_3)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('dt_set_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-kmuPjX_kLC"
   },
   "source": [
    "### 4. Original Features+Interactions + PCA (set-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I6rAG4NZ_jrS",
    "outputId": "ce293503-54ad-41fd-fe10-021306044bde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0374s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0699s.) Setting batch_size=4.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1736s.) Setting batch_size=8.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  50 | elapsed:    2.0s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 3\n",
      "Best criterion: friedman_mse\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 3\n",
      "Best min_samples_leaf: 1\n",
      "Time elapsed: 48.92347836494446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   48.7s finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Number of trees in random forest\n",
    "start=time.time()\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "#criterion\n",
    "criterion=[\"mse\", \"friedman_mse\",\"mae\", \"poisson\"]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = { 'criterion':criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "dr = DecisionTreeRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(dr, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_4, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_criterion = best_regressor.best_estimator_.get_params()['criterion']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best criterion:', best_criterion)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aw9U33bLAa__",
    "outputId": "d38831c2-5610-44a3-9416-ee715add4405"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Decision Tree with best parameters\n",
      "R2 score on train dataset is: 0.6334851962633926\n",
      "R2 score on cv dataset is: 0.6121832153401822\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(criterion = best_criterion,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "dt.fit(train_set_4, y_train)\n",
    "\n",
    "scores = cross_val_score(dt, train_set_4, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = dt.predict(train_set_4)\n",
    "\n",
    "print(\"Predictions on Decision Tree with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVqR-f1iBnP3"
   },
   "outputs": [],
   "source": [
    "y_test=dt.predict(test_set_4)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATQ7b_JHButJ"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('dt_set_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-e924qsyB0MP",
    "outputId": "49b6a05c-fd2a-4e75-f4f3-f1047efa838a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_set_4.joblib']"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dump(dt, 'dt_set_4.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nSiRR9iJFQGw",
    "outputId": "3c25c8e7-575b-46a3-a28d-24d4b2d753d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+-----------------------+---------+---------+\n",
      "|                                  Feature Set                                  |         Model         | Private |  Public |\n",
      "+-------------------------------------------------------------------------------+-----------------------+---------+---------+\n",
      "|                         Original Features+Interactions                        | DecisionTreeRegressor | 0.54427 | 0.54900 |\n",
      "|      Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions     | DecisionTreeRegressor | 0.54487 | 0.54724 |\n",
      "| Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions | DecisionTreeRegressor | 0.53490 | 0.53257 |\n",
      "|                      Original Features+Interactions + PCA                     | DecisionTreeRegressor | 0.53635 | 0.53510 |\n",
      "+-------------------------------------------------------------------------------+-----------------------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "x = PrettyTable()\n",
    "\n",
    "column_names = [\"Feature Set\", \"Model\", \"Private\", \"Public\"]\n",
    "\n",
    "x.add_column(column_names[0], [\"Original Features+Interactions\", \"Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original Features+Interactions + PCA\"])\n",
    "x.add_column(column_names[1], [\"DecisionTreeRegressor\", \"DecisionTreeRegressor\", \"DecisionTreeRegressor\", \"DecisionTreeRegressor\"])  \n",
    "x.add_column(column_names[2], [\"0.54427\",\"0.54487\",\"0.53490\",\"0.53635\"])  \n",
    "x.add_column(column_names[3], [\"0.54900\",\"0.54724\",\"0.53257\",\"0.53510\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R06-HBiEJSLZ"
   },
   "source": [
    "<img src=\"https://i.imgur.com/usag3I3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Re4eaQDVHoI"
   },
   "source": [
    "## 8.4 Random Forest Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_vH8FveFcp"
   },
   "source": [
    "### 1. Original Features+Interactions (set-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "867LZL8XVG7v",
    "outputId": "bd8cdb34-3139-45e9-fd92-b3d99514cd61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 3\n",
      "Best n_estimators: 25\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 2\n",
      "Best min_samples_leaf: 2\n",
      "Time elapsed: 182.66904664039612\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "rf = RandomForestRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(rf, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_1, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_n_estimators = best_regressor.best_estimator_.get_params()['n_estimators']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best n_estimators:', best_n_estimators)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDzcm9mDYxRS",
    "outputId": "daae1c9c-1bbf-4d79-a099-20bdd52c50b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=2,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=25, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = best_n_estimators,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "rf.fit(train_set_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AdqEWoKrZJbq",
    "outputId": "677efaa8-2b98-45e3-c00d-72409e7194cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Randomforest Regressor with best parameters\n",
      "R2 score on train dataset is: 0.6330440095424286\n",
      "R2 score on cv dataset is: 0.6165755115625238\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf, train_set_1, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = rf.predict(train_set_1)\n",
    "\n",
    "print(\"Predictions on Randomforest Regressor with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3cUzKd_d2ZN",
    "outputId": "1bd2ca98-66bf-45e4-c494-83dfc8ea6ffd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_set_1.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dump(rf, 'rf_set_1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCJKb4m7Z0ui"
   },
   "outputs": [],
   "source": [
    "y_test=rf.predict(test_set_1)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('rf_set_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkS40hA6amK9"
   },
   "source": [
    "### 2. Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCowk7MMalJP",
    "outputId": "17a856db-a7ad-4f5b-ff26-be788e9f83aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 36.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 2\n",
      "Best n_estimators: 200\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 25\n",
      "Best min_samples_leaf: 3\n",
      "Time elapsed: 2227.1490206718445\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "rf = RandomForestRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(rf, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_2, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_n_estimators = best_regressor.best_estimator_.get_params()['n_estimators']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best n_estimators:', best_n_estimators)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECPQrEXKnBvD",
    "outputId": "c5e0f566-d6d8-44a7-ee36-2476f4cd14a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=25, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = best_n_estimators,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "rf.fit(train_set_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tL_SHP1e_Xz",
    "outputId": "32b31595-d441-4d33-8710-5bcceae4866a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Randomforest Regressor with best parameters\n",
      "R2 score on train dataset is: 0.6243063310134301\n",
      "R2 score on cv dataset is: 0.619472942594429\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf, train_set_2, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = rf.predict(train_set_2)\n",
    "\n",
    "print(\"Predictions on Randomforest Regressor with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9A_ziXsZd71w",
    "outputId": "867b6b3c-21be-482d-df14-34c28aaf6f45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_set_2.joblib']"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(rf, 'rf_set_2.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvGFxvcjfFKl"
   },
   "outputs": [],
   "source": [
    "y_test=rf.predict(test_set_2)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('rf_set_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szur_M4Ofdrl"
   },
   "source": [
    "### 3. Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOUfOyKSfbgb",
    "outputId": "fc4dd37a-18d4-43d7-9daf-1f1afc37eb0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   54.7s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 24.3min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 32.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 3\n",
      "Best n_estimators: 400\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 5\n",
      "Best min_samples_leaf: 3\n",
      "Time elapsed: 2045.8213617801666\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "rf = RandomForestRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(rf, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_3, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_n_estimators = best_regressor.best_estimator_.get_params()['n_estimators']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best n_estimators:', best_n_estimators)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe8L7aHXnHom",
    "outputId": "7c333d8f-82de-4b75-9987-0a13baa177f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=3,\n",
       "                      min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=400, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = best_n_estimators,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "rf.fit(train_set_3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSIWAJ1vfkw7",
    "outputId": "e496b9b0-7174-4c3f-dc0c-9ca4f53fde97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Randomforest Regressor with best parameters\n",
      "R2 score on train dataset is: 0.6377974416894173\n",
      "R2 score on cv dataset is: 0.6187235063451672\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf, train_set_3, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = rf.predict(train_set_3)\n",
    "\n",
    "print(\"Predictions on Randomforest Regressor with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t3t9fU2od-oj",
    "outputId": "1c531dc7-58af-4379-8556-ba5916d08519"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_set_3.joblib']"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(rf, 'rf_set_3.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfHPNibgfn59"
   },
   "outputs": [],
   "source": [
    "y_test=rf.predict(test_set_3)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('rf_set_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51dazy3FD1yS"
   },
   "source": [
    "### 4. Original Features+Interactions + PCA (set-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZnduQ68D1dH",
    "outputId": "8648644f-ec88-4aaa-8e56-bd918642b62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth: 2\n",
      "Best n_estimators: 10\n",
      "Best max_features: auto\n",
      "Best min_samples_split: 3\n",
      "Best min_samples_leaf: 10\n",
      "Time elapsed: 177.46531510353088\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10, 25, 50, 100, 200, 300, 400, 500]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [2, 3, 5, 10, 15, 20, 25]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 5, 10]\n",
    "\n",
    "# create parameters dictionary\n",
    "parameters = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "#Create a Random Forest Regressor model\n",
    "rf = RandomForestRegressor()\n",
    "#Tune hyperparameters using RandomizedSearchCV\n",
    "regressor = RandomizedSearchCV(rf, param_distributions=parameters, verbose=10, n_jobs=-1)\n",
    "#Fit the model\n",
    "best_regressor = regressor.fit(train_set_4, y_train)\n",
    "# get the best parameters\n",
    "best_max_depth = best_regressor.best_estimator_.get_params()['max_depth']\n",
    "best_n_estimators = best_regressor.best_estimator_.get_params()['n_estimators']\n",
    "best_max_features = best_regressor.best_estimator_.get_params()['max_features']\n",
    "best_min_samples_split = best_regressor.best_estimator_.get_params()['min_samples_split']\n",
    "best_min_samples_leaf = best_regressor.best_estimator_.get_params()['min_samples_leaf']\n",
    "#Print The best parameters\n",
    "print('Best max_depth:', best_max_depth)\n",
    "print('Best n_estimators:', best_n_estimators)\n",
    "print('Best max_features:', best_max_features)\n",
    "print('Best min_samples_split:', best_min_samples_split)\n",
    "print('Best min_samples_leaf:', best_min_samples_leaf)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"Time elapsed: {elapsed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlRFTLEOHQ0r",
    "outputId": "2bb04b84-9ae0-4827-e742-95e6bee71253"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=10,\n",
       "                      min_samples_split=3, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=10, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = best_n_estimators,\n",
    "               max_features = best_max_features,\n",
    "               max_depth = best_max_depth,\n",
    "               min_samples_split = best_min_samples_split,\n",
    "               min_samples_leaf = best_min_samples_leaf)\n",
    "rf.fit(train_set_4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzANd33BHcal",
    "outputId": "7d4472be-5db7-4d05-b261-463a5faa64f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on Randomforest Regressor with best parameters\n",
      "R2 score on train dataset is: 0.6242476012604071\n",
      "R2 score on cv dataset is: 0.6190351800533593\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rf, train_set_4, y_train, cv=5,scoring='r2')\n",
    "y_pred_train = rf.predict(train_set_4)\n",
    "\n",
    "print(\"Predictions on Randomforest Regressor with best parameters\")\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,y_pred_train))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_d5wgqIHvJ8"
   },
   "outputs": [],
   "source": [
    "y_test=rf.predict(test_set_4)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('rf_set_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDOAmSh3PwAF",
    "outputId": "e3473d6c-faf1-441c-c79b-87bd50e7b79f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_set_4.joblib']"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(rf, 'rf_set_4.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "miw2ZEftzVCq",
    "outputId": "76a6c689-692b-43eb-f424-6dfd53024c38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+-----------------------+---------+---------+\n",
      "|                                  Feature Set                                  |         Model         | Private |  Public |\n",
      "+-------------------------------------------------------------------------------+-----------------------+---------+---------+\n",
      "|                         Original Features+Interactions                        | RandomForestRegressor | 0.54781 | 0.55155 |\n",
      "|      Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions     | RandomForestRegressor | 0.54425 | 0.54749 |\n",
      "| Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions | RandomForestRegressor | 0.54641 | 0.54907 |\n",
      "|                      Original Features+Interactions + PCA                     | RandomForestRegressor | 0.54386 | 0.54673 |\n",
      "+-------------------------------------------------------------------------------+-----------------------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "x = PrettyTable()\n",
    "\n",
    "column_names = [\"Feature Set\", \"Model\", \"Private\", \"Public\"]\n",
    "\n",
    "x.add_column(column_names[0], [\"Original Features+Interactions\", \"Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original Features+Interactions + PCA\"])\n",
    "x.add_column(column_names[1], [\"RandomForestRegressor\", \"RandomForestRegressor\", \"RandomForestRegressor\", \"RandomForestRegressor\"])  \n",
    "x.add_column(column_names[2], [\"0.54781\",\"0.54425\",\"0.54641\",\"0.54386\"])  \n",
    "x.add_column(column_names[3], [\"0.55155\",\"0.54749\",\"0.54907\",\"0.54673\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzVrk0fSHwcH"
   },
   "source": [
    "<img src=\"https://i.imgur.com/RIRdtWf.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyqbN3dgkwqM"
   },
   "source": [
    "## 8.4 XGBoost Regressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NOnC0u5k0Ha"
   },
   "source": [
    "### 1. Original Features+Interactions (set-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4JKkLiokwbH",
    "outputId": "750c10f3-b3b4-43b0-afc6-187c184a3b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 17.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:15:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=-1,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_state=0, reg_alpha=0,...\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.7, 0.8, 0.9,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 0.2, 0.3],\n",
       "                                        'max_depth': [2, 3, 4, 5, 10],\n",
       "                                        'min_child_weight': [4, 5],\n",
       "                                        'n_estimators': [50, 100, 200, 500,\n",
       "                                                         1000, 2000],\n",
       "                                        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=10)"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #A parameter grid for XGBoost\n",
    "params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4,5,10],'n_estimators':[50,100,200,500,1000,2000],'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "\n",
    "# Initialize XGB and GridSearch\n",
    "xgb = XGBRegressor(nthread=-1) \n",
    "\n",
    "grid = RandomizedSearchCV(xgb, params,cv=5,verbose=10,scoring='r2',n_jobs=-1)\n",
    "grid.fit(train_set_1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rW-_qTQLk_Un",
    "outputId": "f4305f15-bd5f-4039-a15a-6693e4038252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:16:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:16:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:16:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:16:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:17:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean r2 score of 5 fold CV set is 0.62 with a standard deviation of 0.03\n",
      "[14:17:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "R2 score on train dataset is: 0.6641942597983496\n",
      "R2 score on cv dataset is: 0.6193945544555304\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xgb_set_1 = grid.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xgb_set_1, train_set_1, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xgb_set_1.fit(train_set_1, y_train,eval_metric=r2_score)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xgb_set_1.predict(train_set_1)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gHK561JbeA6x",
    "outputId": "4a257922-55ca-45b9-95d6-019f778a077b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_set_1.joblib']"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_xgb_set_1, 'best_xgb_set_1.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzfgDNJPl-KZ"
   },
   "outputs": [],
   "source": [
    "y_test=best_xgb_set_1.predict(test_set_1)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xgb_set_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9m_TUQsleQJ"
   },
   "source": [
    "### 2. Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Davy0nNIldyk",
    "outputId": "cb3f26f5-6472-4b97-bf58-7747988ca7f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 25.3min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 33.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:51:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=-1,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_state=0, reg_alpha=0,...\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.7, 0.8, 0.9,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 0.2, 0.3],\n",
       "                                        'max_depth': [2, 3, 4, 5, 10],\n",
       "                                        'min_child_weight': [4, 5],\n",
       "                                        'n_estimators': [50, 100, 200, 500,\n",
       "                                                         1000, 2000],\n",
       "                                        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=10)"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #A parameter grid for XGBoost\n",
    "params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4,5,10],'n_estimators':[50,100,200,500,1000,2000],'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "\n",
    "# Initialize XGB and GridSearch\n",
    "xgb = XGBRegressor(nthread=-1) \n",
    "\n",
    "grid = RandomizedSearchCV(xgb, params,cv=5,verbose=10,scoring='r2',n_jobs=-1)\n",
    "grid.fit(train_set_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y6rr62qYlibw",
    "outputId": "a1245827-8884-48da-d509-29f06b6eb468"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:52:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:54:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:55:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:56:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:57:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean r2 score of 5 fold CV set is 0.60 with a standard deviation of 0.02\n",
      "[14:58:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "R2 score on train dataset is: 0.8023543675903718\n",
      "R2 score on cv dataset is: 0.596044855920473\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xgb_set_2 = grid.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xgb_set_2, train_set_2, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xgb_set_2.fit(train_set_2, y_train,eval_metric=r2_score)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xgb_set_2.predict(train_set_2)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7g5yI6ceO9m",
    "outputId": "0309f1a9-fe32-4108-f27b-70644052d469"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_set_2.joblib']"
      ]
     },
     "execution_count": 91,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_xgb_set_2, 'best_xgb_set_2.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3owL4sW1l_A_"
   },
   "outputs": [],
   "source": [
    "y_test=best_xgb_set_2.predict(test_set_2)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xgb_set_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePdvRiA_lqym"
   },
   "source": [
    "### 3. Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-SzxuDalsru",
    "outputId": "44953163-ae23-4d40-d790-d000e13da67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 35.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:38:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=-1,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_state=0, reg_alpha=0,...\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.7, 0.8, 0.9,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 0.2, 0.3],\n",
       "                                        'max_depth': [2, 3, 4, 5, 10],\n",
       "                                        'min_child_weight': [4, 5],\n",
       "                                        'n_estimators': [50, 100, 200, 500,\n",
       "                                                         1000, 2000],\n",
       "                                        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=10)"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #A parameter grid for XGBoost\n",
    "params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4,5,10],'n_estimators':[50,100,200,500,1000,2000],'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "\n",
    "# Initialize XGB and GridSearch\n",
    "xgb = XGBRegressor(nthread=-1) \n",
    "\n",
    "grid = RandomizedSearchCV(xgb, params,cv=5,verbose=10,scoring='r2',n_jobs=-1)\n",
    "grid.fit(train_set_3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKPZ-k54lvW4",
    "outputId": "4689d7f8-e75e-4e9d-d77b-125bad7e0f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:38:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:38:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:38:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:38:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:38:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean r2 score of 5 fold CV set is 0.61 with a standard deviation of 0.03\n",
      "[15:38:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "R2 score on train dataset is: 0.6713202358628905\n",
      "R2 score on cv dataset is: 0.6141363387480163\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xgb_set_3= grid.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xgb_set_3, train_set_3, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xgb_set_3.fit(train_set_3, y_train,eval_metric=r2_score)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xgb_set_3.predict(train_set_3)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmNkQXjPeSHb",
    "outputId": "0a1bc7b5-ca7d-4f1f-e840-abfddc570591"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_set_3.joblib']"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dump(best_xgb_set_3, 'best_xgb_set_3.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbQe49rpl_73"
   },
   "outputs": [],
   "source": [
    "y_test=best_xgb_set_3.predict(test_set_3)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xgb_set_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51tQ3IdmQCbo"
   },
   "source": [
    "### 4. Original Features+Interactions + PCA (set-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8WlEWmkpQENw",
    "outputId": "d607c3c5-bf99-417f-bd72-dc178f619037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   52.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=-1,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_state=0, reg_alpha=0,...\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.7, 0.8, 0.9,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
       "                                                          0.1, 0.2, 0.3],\n",
       "                                        'max_depth': [2, 3, 4, 5, 10],\n",
       "                                        'min_child_weight': [4, 5],\n",
       "                                        'n_estimators': [50, 100, 200, 500,\n",
       "                                                         1000, 2000],\n",
       "                                        'subsample': [0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='r2', verbose=10)"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #A parameter grid for XGBoost\n",
    "params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n",
    "'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4,5,10],'n_estimators':[50,100,200,500,1000,2000],'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]}\n",
    "\n",
    "# Initialize XGB and GridSearch\n",
    "xgb = XGBRegressor(nthread=-1) \n",
    "\n",
    "grid = RandomizedSearchCV(xgb, params,cv=5,verbose=10,scoring='r2',n_jobs=-1)\n",
    "grid.fit(train_set_4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jOdmrZ_QMN6",
    "outputId": "54bd83eb-6f75-4079-e5d0-c637218f940b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:50:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:50:38] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:50:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:51:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean r2 score of 5 fold CV set is 0.62 with a standard deviation of 0.03\n",
      "[15:51:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "R2 score on train dataset is: 0.6663509478939398\n",
      "R2 score on cv dataset is: 0.6155171155997174\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xgb_set_4= grid.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xgb_set_4, train_set_4, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xgb_set_4.fit(train_set_4, y_train,eval_metric=r2_score)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xgb_set_4.predict(train_set_4)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBv01p5IQYfx"
   },
   "outputs": [],
   "source": [
    "y_test=best_xgb_set_4.predict(test_set_4)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xgb_set_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLYRy-1ReZ1r",
    "outputId": "4badc834-e0b6-41c5-ff31-8d44b0880b8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_set_4.joblib']"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_xgb_set_4, 'best_xgb_set_4.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpghU3rD0qbs",
    "outputId": "c1e773fd-bbf1-4031-f0fc-7ac1ee1f16ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+--------------+---------+---------+\n",
      "|                                  Feature Set                                  |    Model     | Private |  Public |\n",
      "+-------------------------------------------------------------------------------+--------------+---------+---------+\n",
      "|                         Original Features+Interactions                        | XGBRegressor | 0.55105 | 0.55191 |\n",
      "|      Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions     | XGBRegressor | 0.53615 | 0.54045 |\n",
      "| Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions | XGBRegressor | 0.54345 | 0.54473 |\n",
      "|                      Original Features+Interactions + PCA                     | XGBRegressor | 0.54941 | 0.54852 |\n",
      "+-------------------------------------------------------------------------------+--------------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "x = PrettyTable()\n",
    "\n",
    "column_names = [\"Feature Set\", \"Model\", \"Private\", \"Public\"]\n",
    "\n",
    "x.add_column(column_names[0], [\"Original Features+Interactions\", \"Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original Features+Interactions + PCA\"])\n",
    "x.add_column(column_names[1], [\"XGBRegressor\", \"XGBRegressor\", \"XGBRegressor\", \"XGBRegressor\"])  \n",
    "x.add_column(column_names[2], [\"0.55105\",\"0.53615\",\"0.54345\",\"0.54941\"])  \n",
    "x.add_column(column_names[3], [\"0.55191\",\"0.54045\",\"0.54473\",\"0.54852\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mb1eu2l1IoPy"
   },
   "source": [
    "<img src=\"https://i.imgur.com/KSeLT7y.png\"/>\n",
    "<img src=\"https://i.imgur.com/LACmwtp.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNPnKknVl2_M"
   },
   "source": [
    "## 8.5 Extra Tree Regressor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZoZOQ8Hj0ny"
   },
   "source": [
    "### 1. Original Features+Interactions (set-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9cWRC42mTA1",
    "outputId": "b5e7aac8-5ace-4979-91c0-476e28507bd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   50.0s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 s, sys: 525 ms, total: 11.7 s\n",
      "Wall time: 11min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xt=ExtraTreesRegressor(random_state=42, n_jobs=-1)\n",
    "parameters = {'n_estimators':[150,200,300,350,400,500,1000],\n",
    "             'max_depth':[2,3,4,5,7,8,10],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,10],\n",
    "             'max_features': [.95],\n",
    "             'min_samples_leaf': [3,4,5,6,7,8,10],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10,100]}\n",
    "\n",
    "xt=RandomizedSearchCV(xt,parameters,cv=10,scoring='r2',return_train_score=True,n_jobs=-1,verbose=5)\n",
    "xt.fit(train_set_1,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VSEaP4BFmcgx",
    "outputId": "fc8180f8-b147-46d9-a23b-17030e880051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean r2 score of 5 fold CV set is 0.62 with a standard deviation of 0.03\n",
      "R2 score on train dataset is: 0.6342421240016307\n",
      "R2 score on cv dataset is: 0.621465481076335\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xt_set_1= xt.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xt_set_1, train_set_1, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xt_set_1.fit(train_set_1, y_train)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xt_set_1.predict(train_set_1)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NfFgnptmpyH"
   },
   "outputs": [],
   "source": [
    "y_test=best_xt_set_1.predict(test_set_1)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xt_set_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJJD20R_SqYw",
    "outputId": "eb617f33-79ce-405a-8e0e-1e1b21824377"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xt_set_1.joblib']"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_xt_set_1, 'best_xt_set_1.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kk8Lw-AYndju"
   },
   "source": [
    "## 2. Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aCV29Wxfnf-p",
    "outputId": "1820bda4-a6e7-4886-fcb6-980d3070bc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 15.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 s, sys: 365 ms, total: 19.7 s\n",
      "Wall time: 15min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neigh=ExtraTreesRegressor(random_state=42, n_jobs=-1)\n",
    "parameters = {'n_estimators':[150,200,300,350,400,500,1000],\n",
    "             'max_depth':[2,3,4,5,7,8,10],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,10],\n",
    "             'max_features': [.95],\n",
    "             'min_samples_leaf': [3,4,5,6,7,8,10],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10,100]}\n",
    "xt=RandomizedSearchCV(neigh,parameters,cv=10,scoring='r2',return_train_score=True,n_jobs=-1,verbose=5)\n",
    "xt.fit(train_set_2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtXDHGPcnjOv",
    "outputId": "bb73b8a9-423c-4e45-b6ac-8f2f1438235a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean r2 score of 5 fold CV set is 0.62 with a standard deviation of 0.03\n",
      "R2 score on train dataset is: 0.6392325885841387\n",
      "R2 score on cv dataset is: 0.6223600938071681\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xt_set_2= xt.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xt_set_2, train_set_2, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xt_set_2.fit(train_set_2, y_train)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xt_set_2.predict(train_set_2)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm1Rt1Emnz54"
   },
   "outputs": [],
   "source": [
    "y_test=best_xt_set_2.predict(test_set_2)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xt_set_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qj60avnTSkuN",
    "outputId": "980ae609-36db-4771-ccb9-57d380b206c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xt_set_2.joblib']"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_xt_set_2, 'best_xt_set_2.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0k7KAyLn4z7"
   },
   "source": [
    "## 3. Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions (Set-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXwDIJnPn6hX",
    "outputId": "194ef39f-4b37-4ab7-9854-10efbdc3a0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 18.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 28.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.4 s, sys: 1.23 s, total: 41.6 s\n",
      "Wall time: 28min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neigh=ExtraTreesRegressor(random_state=42, n_jobs=-1)\n",
    "parameters = {'n_estimators':[150,200,300,350,400,500,1000],\n",
    "             'max_depth':[2,3,4,5,7,8,10],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,10],\n",
    "             'max_features': [.95],\n",
    "             'min_samples_leaf': [3,4,5,6,7,8,10],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10,100]}\n",
    "xt=RandomizedSearchCV(neigh,parameters,cv=10,scoring='r2',return_train_score=True,n_jobs=-1,verbose=5)\n",
    "xt.fit(train_set_3,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8X1_KjVn92p",
    "outputId": "5daf2161-f5f8-4fa8-c729-3a595a98cbb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean r2 score of 5 fold CV set is 0.62 with a standard deviation of 0.03\n",
      "R2 score on train dataset is: 0.643375332817125\n",
      "R2 score on cv dataset is: 0.6223080810766772\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xt_set_3= xt.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xt_set_3, train_set_3, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xt_set_3.fit(train_set_3, y_train)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xt_set_3.predict(train_set_3)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRXYUOiroeZh"
   },
   "outputs": [],
   "source": [
    "y_test=best_xt_set_3.predict(test_set_3)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xt_set_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMQ-3ALISx2J",
    "outputId": "ece29ef1-9471-4460-e2c7-e50933bf7d3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xt_set_3.joblib']"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_xt_set_3, 'best_xt_set_3.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20ptvZexS1Si"
   },
   "source": [
    "## 4. Original Features+Interactions + PCA (set-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eVzF_c60S3sI",
    "outputId": "381b7fee-6b53-4d62-b6e3-c2958b77d6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 599 ms, total: 11.7 s\n",
      "Wall time: 13min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neigh=ExtraTreesRegressor(random_state=42, n_jobs=-1)\n",
    "parameters = {'n_estimators':[150,200,300,350,400,500,1000],\n",
    "             'max_depth':[2,3,4,5,7,8,10],\n",
    "             'min_samples_split':[2,3,4,5,6,7,8,10],\n",
    "             'max_features': [.95],\n",
    "             'min_samples_leaf': [3,4,5,6,7,8,10],\n",
    "             'min_impurity_decrease':[1e-5,1e-4,1e-3,1e-2,1e-1,0,1,10,100]}\n",
    "xt=RandomizedSearchCV(neigh,parameters,cv=10,scoring='r2',return_train_score=True,n_jobs=-1,verbose=5)\n",
    "xt.fit(train_set_4,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EBt0SfRrS6Kq",
    "outputId": "e70e0ba4-4310-42ba-d10b-2a4d9e9cf36e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean r2 score of 5 fold CV set is 0.62 with a standard deviation of 0.03\n",
      "R2 score on train dataset is: 0.6348008353540164\n",
      "R2 score on cv dataset is: 0.6209364519022664\n"
     ]
    }
   ],
   "source": [
    "#cross validation \n",
    "\n",
    "best_xt_set_4= xt.best_estimator_\n",
    "\n",
    "scores = cross_val_score(best_xt_set_4, train_set_4, y_train, cv=5,scoring='r2')\n",
    "print(\"Mean r2 score of 5 fold CV set is %0.2f with a standard deviation of %0.2f\"%(np.mean(scores),np.std(scores)))\n",
    "best_xt_set_4.fit(train_set_4, y_train)\n",
    "\n",
    "\n",
    "print('R2 score on train dataset is:',r2_score(y_train,best_xt_set_4.predict(train_set_4)))\n",
    "print('R2 score on cv dataset is:',np.mean(scores))\n",
    "#print('RMLSE on cv dataset is:',np.sqrt(mean_squared_log_error(y_cv_cleaned, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2P3z4RVZTCwL"
   },
   "outputs": [],
   "source": [
    "y_test=best_xt_set_4.predict(test_set_4)\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test\n",
    "submission.to_csv('xt_set_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iW_BghqRTELF",
    "outputId": "ba0ea7b6-ad96-4d07-8d9e-ad49079b343c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xt_set_4.joblib']"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_xt_set_4, 'best_xt_set_4.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3qoa5EK43t4",
    "outputId": "4766305d-1eab-48c4-d1ab-1881e57f7b1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+---------------------+---------+---------+\n",
      "|                                  Feature Set                                  |        Model        | Private |  Public |\n",
      "+-------------------------------------------------------------------------------+---------------------+---------+---------+\n",
      "|                         Original Features+Interactions                        | ExtraTreesRegressor | 0.54761 | 0.54985 |\n",
      "|      Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions     | ExtraTreesRegressor | 0.54844 | 0.55075 |\n",
      "| Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions | ExtraTreesRegressor | 0.55048 | 0.55274 |\n",
      "|                      Original Features+Interactions + PCA                     | ExtraTreesRegressor | 0.55032 | 0.55183 |\n",
      "+-------------------------------------------------------------------------------+---------------------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "\n",
    "x = prettytable.PrettyTable()\n",
    "\n",
    "column_names = [\"Feature Set\", \"Model\", \"Private\", \"Public\"]\n",
    "\n",
    "x.add_column(column_names[0], [\"Original Features+Interactions\", \"Original Features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection features + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original Features+Interactions + PCA\"])\n",
    "x.add_column(column_names[1], [\"ExtraTreesRegressor\", \"ExtraTreesRegressor\", \"ExtraTreesRegressor\", \"ExtraTreesRegressor\"])  \n",
    "x.add_column(column_names[2], [\"0.54761\",\"0.54844\",\"0.55048\",\"0.55032\"])  \n",
    "x.add_column(column_names[3], [\"0.54985\",\"0.55075\",\"0.55274\",\"0.55183\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3f3p6qZHm1H"
   },
   "source": [
    "<img src=\"https://i.imgur.com/yM5hJH0.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAUf-fYX4gOs"
   },
   "source": [
    " ## Weighted Average of XgBoost and Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gx_Dx4-iIq7g",
    "outputId": "6ef8eb20-a65a-49dd-9d40-641aa3bd82d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgboost_set_1 = load('best_xgb_set_1.joblib')\n",
    "xt_set_3 = load('best_xt_set_3.joblib')\n",
    "xt_set_4 = load('best_xt_set_4.joblib')\n",
    "y_test_set_1_xgb = xgboost_set_1.predict(test_set_1)\n",
    "y_test_set_3_xt = xt_set_3.predict(test_set_3)\n",
    "y_test_set_4_xt = xt_set_4.predict(test_set_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qf94RLx267r0"
   },
   "source": [
    "## XgBoost on Set-1 and Extra Trees on Set-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73FL9VfT7J_p"
   },
   "source": [
    "### 1. w1=0.3 and w2=0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cxFTGL0Ju0F"
   },
   "outputs": [],
   "source": [
    "y_test_avg = 0.3 * y_test_set_1_xgb + 0.7* y_test_set_3_xt\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test_avg\n",
    "submission.to_csv('xt_xgb_wavg_1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFG_NiqT7hsh"
   },
   "source": [
    "### 2. w1=0.5 and w2=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pH-0rtmvK7-8"
   },
   "outputs": [],
   "source": [
    "y_test_avg = 0.5 * y_test_set_1_xgb + 0.5* y_test_set_3_xt\n",
    "\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test_avg\n",
    "submission.to_csv('xt_xgb_wavg_2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weZytF4Z7p0r"
   },
   "source": [
    "### 3. w1=0.4 and w2=0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgOjNl3eMHlj"
   },
   "outputs": [],
   "source": [
    "y_test_avg = 0.4 * y_test_set_1_xgb + 0.6* y_test_set_3_xt\n",
    "\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test_avg\n",
    "submission.to_csv('xt_xgb_wavg_3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ikrp-CcN7yDd"
   },
   "source": [
    "## XgBoost on Set-1 and Extra Trees on Set-3 and Extra Trees on Set-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohYqmW3r8Fjf"
   },
   "source": [
    "## 1. W1 = 0.45 and W2 = 0.45 and W4 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Th_cgDeP6Ls"
   },
   "outputs": [],
   "source": [
    "y_test_avg = 0.45 * y_test_set_1_xgb + 0.45* y_test_set_3_xt + 0.1*y_test_set_4_xt\n",
    "\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test_avg\n",
    "submission.to_csv('xt_xgb_wavg_4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGMGt1rz8jv4"
   },
   "source": [
    "## 2. W1 = 0.5 and W2 = 0.4 and W4 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkcDJhpNRW8-"
   },
   "outputs": [],
   "source": [
    "y_test_avg = 0.5 * y_test_set_1_xgb + 0.40* y_test_set_3_xt + 0.1*y_test_set_4_xt\n",
    "\n",
    "submission=pd.DataFrame()\n",
    "submission['ID'] = test['ID']\n",
    "submission['y'] = y_test_avg\n",
    "submission.to_csv('xt_xgb_wavg_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8k1T_RU1_K_a",
    "outputId": "dfcf3eaa-3a12-42ee-d296-740150c4b3b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+---------------------------------------------+---------+---------+\n",
      "|                           Feature Set                            |                    Model                    | Private |  Public |\n",
      "+------------------------------------------------------------------+---------------------------------------------+---------+---------+\n",
      "|        Original+Interactions & Original+Interactions+PCA         |          0.3*Xgboost+0.7*ExtraTrees         | 0.55201 | 0.55382 |\n",
      "|        Original+Interactions & Original+Interactions+PCA         |          0.5*Xgboost+0.5*ExtraTrees         | 0.55238 | 0.55390 |\n",
      "|        Original+Interactions & Original+Interactions+PCA         |          0.4*Xgboost+0.6*ExtraTrees         | 0.55226 | 0.55392 |\n",
      "| Original+Interactions & Original+Interactions+PCA & Original+PCA | 0.45*Xgboost+0.45*ExtraTrees+0.1*ExtraTrees | 0.55242 | 0.55392 |\n",
      "| Original+Interactions & Original+Interactions+PCA & Original+PCA |  0.5*Xgboost+0.4*ExtraTrees+0.1*ExtraTrees  | 0.55247 | 0.55389 |\n",
      "+------------------------------------------------------------------+---------------------------------------------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "\n",
    "x = prettytable.PrettyTable()\n",
    "\n",
    "column_names = [\"Feature Set\", \"Model\", \"Private\", \"Public\"]\n",
    "\n",
    "x.add_column(column_names[0], [\"Original+Interactions & Original+Interactions+PCA\",\"Original+Interactions & Original+Interactions+PCA\",\"Original+Interactions & Original+Interactions+PCA\",\"Original+Interactions & Original+Interactions+PCA & Original+PCA\",\"Original+Interactions & Original+Interactions+PCA & Original+PCA\"])\n",
    "x.add_column(column_names[1], [\"0.3*Xgboost+0.7*ExtraTrees\",\"0.5*Xgboost+0.5*ExtraTrees\", \"0.4*Xgboost+0.6*ExtraTrees\",\"0.45*Xgboost+0.45*ExtraTrees+0.1*ExtraTrees\", \"0.5*Xgboost+0.4*ExtraTrees+0.1*ExtraTrees\"])  \n",
    "x.add_column(column_names[2], [\"0.55201\",\"0.55238\",\"0.55226\",\"0.55242\",\"0.55247\"])  \n",
    "x.add_column(column_names[3], [\"0.55382\",\"0.55390\",\"0.55392\",\"0.55392\",\"0.55389\"])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id3OXp-oHMiH"
   },
   "source": [
    "<img src=\"https://i.imgur.com/gomZYq5.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjgHwb8eKR2o"
   },
   "source": [
    "# Final Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A8vdAolbFfIE",
    "outputId": "8d5abce2-5e1c-4091-8671-88edb1ceb252"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+---------------------------------------------+---------+---------+\n",
      "|                             Feature Set                              |                   Model(s)                  | Private |  Public |\n",
      "+----------------------------------------------------------------------+---------------------------------------------+---------+---------+\n",
      "|                        Original+Interactions                         |                     KNN                     | 0.50414 | 0.52808 |\n",
      "|     Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions      |                     KNN                     | 0.43260 | 0.45090 |\n",
      "| Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions |                     KNN                     | 0.41756 | 0.43052 |\n",
      "|                     Original +Interactions + PCA                     |                     KNN                     | 0.48654 | 0.50760 |\n",
      "|                        Original+Interactions                         |                   LassoCV                   | 0.53576 | 0.53580 |\n",
      "|     Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions      |                   LassoCV                   | 0.53546 | 0.53337 |\n",
      "| Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions |                   LassoCV                   | 0.53490 | 0.53257 |\n",
      "|                     Original +Interactions + PCA                     |                   LassoCV                   | 0.53635 | 0.53510 |\n",
      "|                        Original+Interactions                         |            DecisionTreeRegressor            | 0.54427 | 0.54900 |\n",
      "|     Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions      |            DecisionTreeRegressor            | 0.54487 | 0.54724 |\n",
      "| Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions |            DecisionTreeRegressor            | 0.53490 | 0.53257 |\n",
      "|                     Original +Interactions + PCA                     |            DecisionTreeRegressor            | 0.53635 | 0.53510 |\n",
      "|                        Original+Interactions                         |            RandomForestRegressor            | 0.54781 | 0.55155 |\n",
      "|     Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions      |            RandomForestRegressor            | 0.54425 | 0.54749 |\n",
      "| Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions |            RandomForestRegressor            | 0.54641 | 0.54907 |\n",
      "|                     Original +Interactions + PCA                     |            RandomForestRegressor            | 0.54386 | 0.54673 |\n",
      "|                        Original+Interactions                         |                 XGBRegressor                | 0.55105 | 0.55191 |\n",
      "|     Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions      |                 XGBRegressor                | 0.53615 | 0.54045 |\n",
      "| Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions |                 XGBRegressor                | 0.54345 | 0.54473 |\n",
      "|                     Original +Interactions + PCA                     |                 XGBRegressor                | 0.54941 | 0.54852 |\n",
      "|                        Original+Interactions                         |             ExtraTreesRegressor             | 0.54761 | 0.54985 |\n",
      "|     Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions      |             ExtraTreesRegressor             | 0.54844 | 0.55075 |\n",
      "| Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions |             ExtraTreesRegressor             | 0.55048 | 0.55274 |\n",
      "|                     Original +Interactions + PCA                     |             ExtraTreesRegressor             | 0.55032 | 0.55183 |\n",
      "|          Original+Interactions & Original+Interactions+PCA           |          0.3*Xgboost+0.7*ExtraTrees         | 0.55201 | 0.55382 |\n",
      "|          Original+Interactions & Original+Interactions+PCA           |          0.5*Xgboost+0.5*ExtraTrees         | 0.55238 | 0.55390 |\n",
      "|          Original+Interactions & Original+Interactions+PCA           |          0.4*Xgboost+0.6*ExtraTrees         | 0.55226 | 0.55392 |\n",
      "|   Original+Interactions & Original+Interactions+PCA & Original+PCA   | 0.45*Xgboost+0.45*ExtraTrees+0.1*ExtraTrees | 0.55242 | 0.55392 |\n",
      "|   Original+Interactions & Original+Interactions+PCA & Original+PCA   |  0.5*Xgboost+0.4*ExtraTrees+0.1*ExtraTrees  | 0.55247 | 0.55389 |\n",
      "+----------------------------------------------------------------------+---------------------------------------------+---------+---------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = prettytable.PrettyTable()\n",
    "column_names = [\"Feature Set\", \"Model(s)\", \"Private\", \"Public\"]\n",
    "x.add_column(column_names[0], [\"Original+Interactions\", \"Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original +Interactions + PCA\",\"Original+Interactions\", \"Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original +Interactions + PCA\",\"Original+Interactions\", \"Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original +Interactions + PCA\",\"Original+Interactions\", \"Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original +Interactions + PCA\",\"Original+Interactions\", \"Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original +Interactions + PCA\",\"Original+Interactions\", \"Original + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\", \"Feature Selection + Projections (ICA+PCA+SVD+GRP+SRP) + Interactions\",\"Original +Interactions + PCA\",\"Original+Interactions & Original+Interactions+PCA\",\"Original+Interactions & Original+Interactions+PCA\",\"Original+Interactions & Original+Interactions+PCA\",\"Original+Interactions & Original+Interactions+PCA & Original+PCA\",\"Original+Interactions & Original+Interactions+PCA & Original+PCA\"])\n",
    "x.add_column(column_names[1], [\"KNN\", \"KNN\", \"KNN\", \"KNN\",\"LassoCV\", \"LassoCV\", \"LassoCV\", \"LassoCV\",\"DecisionTreeRegressor\", \"DecisionTreeRegressor\", \"DecisionTreeRegressor\", \"DecisionTreeRegressor\",\"RandomForestRegressor\", \"RandomForestRegressor\", \"RandomForestRegressor\", \"RandomForestRegressor\",\"XGBRegressor\", \"XGBRegressor\", \"XGBRegressor\", \"XGBRegressor\",\"ExtraTreesRegressor\", \"ExtraTreesRegressor\", \"ExtraTreesRegressor\", \"ExtraTreesRegressor\",\"0.3*Xgboost+0.7*ExtraTrees\",\"0.5*Xgboost+0.5*ExtraTrees\", \"0.4*Xgboost+0.6*ExtraTrees\",\"0.45*Xgboost+0.45*ExtraTrees+0.1*ExtraTrees\", \"0.5*Xgboost+0.4*ExtraTrees+0.1*ExtraTrees\"])  \n",
    "x.add_column(column_names[2], [\"0.50414\",\"0.43260\",\"0.41756\",\"0.48654\",\"0.53576\",\"0.53546\",\"0.53490\",\"0.53635\",\"0.54427\",\"0.54487\",\"0.53490\",\"0.53635\",\"0.54781\",\"0.54425\",\"0.54641\",\"0.54386\",\"0.55105\",\"0.53615\",\"0.54345\",\"0.54941\",\"0.54761\",\"0.54844\",\"0.55048\",\"0.55032\",\"0.55201\",\"0.55238\",\"0.55226\",\"0.55242\",\"0.55247\"])  \n",
    "x.add_column(column_names[3], [\"0.52808\",\"0.45090\",\"0.43052\",\"0.50760\",\"0.53580\",\"0.53337\",\"0.53257\",\"0.53510\",\"0.54900\",\"0.54724\",\"0.53257\",\"0.53510\",\"0.55155\",\"0.54749\",\"0.54907\",\"0.54673\",\"0.55191\",\"0.54045\",\"0.54473\",\"0.54852\",\"0.54985\",\"0.55075\",\"0.55274\",\"0.55183\",\"0.55382\",\"0.55390\",\"0.55392\",\"0.55392\",\"0.55389\"])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewVzYxQOh2Te"
   },
   "source": [
    "# Conclusions \n",
    "\n",
    "1. Xgboost and Extra Trees regressor are my two best models here.\n",
    "\n",
    "2. So just by using feature set 1 that is original features and the interactions with xgboost model I am able to score a decent score in the private leader board.\n",
    "\n",
    "3. By take the weighted average of my two best models on some combinations of the feature set I have created I am able to get a pretty very good score.\n",
    "\n",
    "4. Interactions and taking the weighted average of different models predictions on various feature sets was really helpful in getting a good score.\n",
    "\n",
    "5. By best score is 0.55247 and it is in the top 4% of the kaggle's private leadboard.\n",
    "\n",
    "6. For creating the final production pipleline I am using the simple xgboost model which I trained on my original feature set + interactions. \n",
    "\n",
    "7. Next step will be to try stacking to improve my current best score.\n",
    "\n",
    "8. I would also like to give a shot to deep learning as well for automatic feature set creating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/PlKw7vz.png<img src=\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Case_Study_1_ML_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
